{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29e44cd-ef7c-4723-993c-8725b1e2dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bb23b5-e66f-44cf-85e8-1c6c8684069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------  \n",
    "# 0) Paths & basic config                                  \n",
    "# ------------------------------------------------------- \n",
    "import os\n",
    "CACHE_DIR = \"/mnt/raid10/ak-research-01/ak-research-01/codes/.cache\"\n",
    "\n",
    "PROCESSED_ROOT = (\n",
    "    \"/mnt/raid10/ak-research-01/ak-research-01/codes/steer-vector/\"\n",
    "    \"latentqa/1_feature_description/dataset/processed_dataset\"\n",
    ")\n",
    "\n",
    "# Layers L01â€“L13, skipping L03\n",
    "layers = list(range(1, 32))\n",
    "if 3 in layers:\n",
    "    layers.remove(3)\n",
    "\n",
    "TRAIN_JSON_LIST = [\n",
    "    os.path.join(PROCESSED_ROOT, f\"L{layer:02d}\", \"train.jsonl\")\n",
    "    for layer in layers\n",
    "]\n",
    "\n",
    "TEST_JSON_LIST = [\n",
    "    os.path.join(PROCESSED_ROOT, f\"L{layer:02d}\", \"test.jsonl\")\n",
    "    for layer in layers\n",
    "]\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
    "MAX_LENGTH = 128   # you can increase if explanations are long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f25b11c-9053-41b3-850c-5ca67621bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce09275e20344e6187d6dbf0e406b74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# 1) Load explainer model and tokenizer\n",
    "# -------------------------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))  # in case we add special tokens\n",
    "model.train()\n",
    "dtype = next(model.parameters()).dtype\n",
    "\n",
    "device = model.device  # \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb6884f-cace-4c2e-bd4f-0bb71c47d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) Special tokens and templates\n",
    "# -------------------------------------------------------\n",
    "# Add [s], [e] if needed\n",
    "SPECIAL_TOKENS = {\"additional_special_tokens\": [\"[s]\", \"[e]\"]}\n",
    "need_add = any(tok not in tokenizer.get_vocab()\n",
    "               for tok in SPECIAL_TOKENS[\"additional_special_tokens\"])\n",
    "if need_add:\n",
    "    tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "ID_S = tokenizer.convert_tokens_to_ids(\"[s]\")\n",
    "ID_E = tokenizer.convert_tokens_to_ids(\"[e]\")\n",
    "\n",
    "# >>> ADD THIS BLOCK <<<\n",
    "# Use EOS as padding token (typical for LLaMA-style models)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "# <<< END BLOCK >>>\n",
    "\n",
    "FEATURE_TEMPLATES = [\n",
    "    \"At layer {layer}, [s]v[e] encodes\",\n",
    "    \"[s]v[e] activates at layer {layer} for\",\n",
    "    \"We can describe [s]v[e] at layer {layer} as encoding\",\n",
    "    \"Generate a description of this feature at layer {layer}: [s]v[e].\",\n",
    "    \"What does [s]v[e] mean at layer {layer}?\",\n",
    "    \"[s]v[e] activates at layer {layer} for inputs with the following features:\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_feature_prompt(layer: int, template_id: int | None = None) -> str:\n",
    "    if template_id is None:\n",
    "        template_id = random.randrange(len(FEATURE_TEMPLATES))\n",
    "    return FEATURE_TEMPLATES[template_id].format(layer=layer) + \" \"\n",
    "\n",
    "\n",
    "def find_v_index(prompt_ids: List[int]) -> int:\n",
    "    \"\"\"Find index of the token between [s] and [e] (the 'v' position).\"\"\"\n",
    "    ids = torch.tensor(prompt_ids, dtype=torch.long)\n",
    "\n",
    "    s_positions = (ids == ID_S).nonzero(as_tuple=True)[0]\n",
    "    if len(s_positions) == 0:\n",
    "        raise ValueError(\"Prompt does not contain [s] token.\")\n",
    "    s_idx = int(s_positions[0].item())\n",
    "\n",
    "    e_positions = (ids == ID_E).nonzero(as_tuple=True)[0]\n",
    "    e_positions = e_positions[e_positions > s_idx]\n",
    "    if len(e_positions) == 0:\n",
    "        raise ValueError(\"Prompt does not contain [e] token after [s].\")\n",
    "    e_idx = int(e_positions[0].item())\n",
    "\n",
    "    mid_positions = list(range(s_idx + 1, e_idx))\n",
    "    if len(mid_positions) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Expected exactly one token between [s] and [e], got {len(mid_positions)}.\"\n",
    "        )\n",
    "    return mid_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8dd64a1-cc5b-4743-8dbd-bca3d1cc26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 3) Dataset\n",
    "# -------------------------------------------------------\n",
    "def load_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "        \n",
    "class FeatureExplanationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item:\n",
    "        - builds a prompt with [s]v[e] for the given layer\n",
    "        - concatenates the gold description\n",
    "        - prepares:\n",
    "            input_ids   : prompt + description\n",
    "            attention   : mask\n",
    "            labels      : -100 on prompt, ids on description\n",
    "            v           : SAE feature vector (direction)\n",
    "            v_idx       : index of 'v' token in the sequence\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        json_paths: List[str],   # <<< list of paths\n",
    "        tokenizer,\n",
    "        max_length: int = 128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # load and concatenate all jsonl files\n",
    "        self.data: List[Dict[str, Any]] = []\n",
    "        for p in json_paths:\n",
    "            self.data.extend(load_jsonl(p))\n",
    "\n",
    "        # --- randomly keep 70% ---\n",
    "        random.shuffle(self.data)                          # in-place shuffle\n",
    "        k = int(len(self.data) * 0.30)                     # number to keep\n",
    "        self.data = self.data[:k]                          # subsample\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        layer = int(item[\"layer\"])\n",
    "        description = item[\"description\"]\n",
    "        vector = item[\"vector\"]  # list or numpy; we convert to tensor\n",
    "\n",
    "        # ---- prompt with [s]v[e] ----\n",
    "        prompt = make_feature_prompt(layer)\n",
    "        prompt_enc = self.tokenizer(\n",
    "            prompt,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        prompt_ids = prompt_enc[\"input_ids\"]\n",
    "\n",
    "        # index of 'v' in the prompt\n",
    "        v_idx = find_v_index(prompt_ids)\n",
    "\n",
    "        # ---- explanation tokens ----\n",
    "        # we add EOS to description so model learns to stop\n",
    "        expl_text = description + self.tokenizer.eos_token\n",
    "        expl_enc = self.tokenizer(\n",
    "            expl_text,\n",
    "            add_special_tokens=False,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        expl_ids = expl_enc[\"input_ids\"]\n",
    "\n",
    "        # ---- full sequence = prompt + explanation ----\n",
    "        input_ids = prompt_ids + expl_ids\n",
    "        if len(input_ids) > self.max_length:\n",
    "            input_ids = input_ids[: self.max_length]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # labels: ignore prompt tokens\n",
    "        labels = [-100] * len(prompt_ids) + expl_ids\n",
    "        if len(labels) > self.max_length:\n",
    "            labels = labels[: self.max_length]\n",
    "\n",
    "        # make sure everything has same length\n",
    "        assert len(input_ids) == len(labels) == len(attention_mask)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "            \"v\": vector,\n",
    "            \"v_idx\": v_idx,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e572006-4688-413e-a8ff-141d5d383239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3) Collator that injects v at v_idx\n",
    "# ---------------------------------------------------------\n",
    "@dataclass\n",
    "class ContinuousTokenCollator:\n",
    "    tokenizer: Any\n",
    "    model: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids_list = [torch.tensor(f[\"input_ids\"], dtype=torch.long) for f in features]\n",
    "        attn_list      = [torch.tensor(f[\"attention_mask\"], dtype=torch.long) for f in features]\n",
    "        labels_list    = [torch.tensor(f[\"labels\"], dtype=torch.long) for f in features]\n",
    "        v_list         = [torch.tensor(f[\"v\"], dtype=torch.float32) for f in features]\n",
    "        v_idx_list     = [int(f[\"v_idx\"]) for f in features]\n",
    "\n",
    "        # pad input_ids + attention\n",
    "        batch_enc = self.tokenizer.pad(\n",
    "            {\"input_ids\": input_ids_list, \"attention_mask\": attn_list},\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = batch_enc[\"input_ids\"]        # [B, L]\n",
    "        attention_mask = batch_enc[\"attention_mask\"]\n",
    "\n",
    "        # pad labels\n",
    "        labels = self.tokenizer.pad(\n",
    "            {\"input_ids\": labels_list},\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        # embed and inject v at v_idx\n",
    "        emb_layer = self.model.get_input_embeddings()\n",
    "        inputs_embeds = emb_layer(input_ids)  # [B, L, d_model]\n",
    "\n",
    "        for i, (v, v_idx) in enumerate(zip(v_list, v_idx_list)):\n",
    "            v = v.to(inputs_embeds.device, dtype=inputs_embeds.dtype)\n",
    "            v = v / (v.norm() + 1e-8)\n",
    "            if v_idx < inputs_embeds.size(1):\n",
    "                inputs_embeds[i, v_idx, :] = v\n",
    "\n",
    "        return {\n",
    "            \"inputs_embeds\": inputs_embeds.to(device),\n",
    "            \"attention_mask\": attention_mask.to(device),\n",
    "            \"labels\": labels.to(device),\n",
    "        }\n",
    "\n",
    "\n",
    "train_dataset = FeatureExplanationDataset(TRAIN_JSON_LIST, tokenizer, MAX_LENGTH)\n",
    "eval_dataset = FeatureExplanationDataset(TEST_JSON_LIST, tokenizer, MAX_LENGTH)\n",
    "\n",
    "data_collator = ContinuousTokenCollator(tokenizer=tokenizer, model=model)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6450c26d-152d-4af5-894e-59fed1d6af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 50 | Loss 1.5600\n",
      "Epoch 1 | Step 100 | Loss 1.2246\n",
      "Epoch 1 | Step 150 | Loss 1.1549\n",
      "Epoch 1 | Step 200 | Loss 1.1354\n",
      "Epoch 1 | Step 250 | Loss 1.0897\n",
      "[Eval] Epoch 1 | Loss 1.1093\n",
      "Epoch 2 | Step 50 | Loss 0.8720\n",
      "Epoch 2 | Step 100 | Loss 0.8562\n",
      "Epoch 2 | Step 150 | Loss 0.8464\n",
      "Epoch 2 | Step 200 | Loss 0.8878\n",
      "Epoch 2 | Step 250 | Loss 0.8987\n",
      "[Eval] Epoch 2 | Loss 1.1697\n",
      "Epoch 3 | Step 50 | Loss 0.5375\n",
      "Epoch 3 | Step 100 | Loss 0.5603\n",
      "Epoch 3 | Step 150 | Loss 0.5462\n",
      "Epoch 3 | Step 200 | Loss 0.5989\n",
      "Epoch 3 | Step 250 | Loss 0.5688\n",
      "[Eval] Epoch 3 | Loss 1.3371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/mnt/raid10/ak-research-01/ak-research-01/codes/steer-vector/latentqa/1_feature_description/model/explainer_L01_L31_ckpt/tokenizer_config.json',\n",
       " '/mnt/raid10/ak-research-01/ak-research-01/codes/steer-vector/latentqa/1_feature_description/model/explainer_L01_L31_ckpt/special_tokens_map.json',\n",
       " '/mnt/raid10/ak-research-01/ak-research-01/codes/steer-vector/latentqa/1_feature_description/model/explainer_L01_L31_ckpt/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4) Simple training loop (cross-entropy on explanation)\n",
    "# ---------------------------------------------------------\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            inputs_embeds=batch[\"inputs_embeds\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (step + 1) % 50 == 0:\n",
    "            avg = total_loss / 50\n",
    "            print(f\"Epoch {epoch+1} | Step {step+1} | Loss {avg:.4f}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "    # quick eval after each epoch\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_steps = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            outputs = model(\n",
    "                inputs_embeds=batch[\"inputs_embeds\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                labels=batch[\"labels\"],\n",
    "            )\n",
    "            eval_loss += outputs.loss.item()\n",
    "            eval_steps += 1\n",
    "    if eval_steps > 0:\n",
    "        print(f\"[Eval] Epoch {epoch+1} | Loss {eval_loss / eval_steps:.4f}\")\n",
    "\n",
    "\n",
    "DATA_DIR = \"/mnt/raid10/ak-research-01/ak-research-01/codes/steer-vector/latentqa/1_feature_description/model\"\n",
    "\n",
    "# Save fine-tuned explainer\n",
    "model_name = \"explainer_L01_L31_ckpt\"\n",
    "os.makedirs(os.path.join(DATA_DIR, model_name), exist_ok=True)\n",
    "model.save_pretrained(os.path.join(DATA_DIR, model_name))\n",
    "tokenizer.save_pretrained(os.path.join(DATA_DIR, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b58da-7560-4046-bf88-5ce9bcfbb44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de581d-d3c8-4bb5-b565-b17628ae9ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be5375-da87-4fb5-97f5-f95fde152bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
